<!DOCTYPE html>
<html lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<link rel="shortcut icon" href="ccglab2.ico" />
<title>CCGlab: CCG in Common Lisp</title>
<meta name="keywords" content="categorial grammar,grammar,cognitive science,linguistics"> 
</head>

<big><big><code><b>CCGlab</b></code></big></big>
<br>
<hr>
<font face="Times New Roman">

<p>
<big><code>CCGlab</code></big> is a tool to experiment with  Combinatory Categorial Grammar (CCG), from   
quick check of a linguistic analysis in CCG, to large-scale development
of  grammars and models.

<p>
<big><code>CCGlab</code></big> grammars are written much like in CCG papers. The output is in papers format (well, almost).  

<p>-Cem Bozsahin


<p> 
It implements all established combinators of CCG, also, experimental ones, in all variants and powers.
Unary rules, slash modalities,
and meta-categories such as (X\X)/X have been implemented. The manual below
describes the range of possible <big><code>CCGlab</code></big> grammars.

<p>It also implements probabilistic CCG, aka. pCCG. In the plain vanilla version, only lexical features are used, which you can amend.
Parameter estimation and update are provided with or without extrapolation.
Therefore model training is possible.
Models and grammars use the same format.

<p> In `parsing' mode, <code><big>CCGlab</code></big> 
delivers all logical forms that are derivable for the given string.
In `ranking' mode, it gives the most likely logical form for a string, given training from data so far, its most likely derivation, and the most likely derivation for any LF
for the string. Lower-ranking parsers are available too, if demanded.
Both modes are based on the same CKY parse engine and the same CCG grammar format.

<p> The main features of <big><code>CCGlab</code></big> are:
<ul>
<li> The logical form is associated with the entire category, via self-contained and lisp-free lambda-calculus.
<li> Structural unification plays no linguistic role; basic categories and their atomic features are matched for term consistency only.
<li> There are no built-in or universally assumed basic category inventory. Everything projects from a lexicalized grammar.
<li> Probabilistic CCG has been integrated into the system. It is the basis of training for ranking.
<li> By default, standard CCG combinators are available all the time, in their powers (linear, quadratic, cubic). 
 They all have on/off switches for experimentation.
<li> Facilities are provided for type-raising, such as 
unary rules and morpholexical generalizations. There is a compiler for it.
<li> Parsing mode is designed for linguistically-motivated grammars, and ranking
	mode for statistically-trained grammars. 
	Competence and performance grammars have the same shape but different function.
Feature counts are always calculated by CKY independent of mode of use. 
<li>
Parsing mode is also possible in a statistically-trained grammar, and ranking mode in a linguistically-motivated grammar.
The first one is helpful in fine-tuning a model. The second use is  helpful in prioritizing lexical assumptions.
</ul>

<hr>

<h4><big><code>CCGlab</code></big> resources</h4>
<table border="0">
<tr> <td> <a href="CCGlab-manual.pdf">Manual</a></td>
     <td> Latest manual. For reference, and for sneak preview.</td></tr>
<tr><td> <a href="https://github.com/bozsahin/ccglab">Repository</a></td><td> Github repo (with installer).
     Also contains sample grammars and release notes.</td></tr>
<tr> <td> <a href="http://www.gnu.org/licenses/gpl">License</a> </td>
     <td> Publicly available software, with GNU General Public License. One day it will be hardware.
</tr>
<tr>
<td> <a href="tips.html">Tips</a></td>
<td>Practical information about writing <code>.ccg </code> grammars, working with projects, updates, etc.</td></tr>
</table>
<hr>
<hr>
</font>
</body>
</html>
